{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 300_gpt_tuning_v2\n",
    "\n",
    "> In this notebook we will fine tune multiple GPT 3.5 models with what we learned from the first set and with progressive and conservative models seperate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import openai\n",
    "import json\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient.errors import HttpError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable apis with keys. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/danie/OneDrive/Desktop/buffed_perspective_api_key_.txt\") as f:\n",
    "    api_key = f.readline()\n",
    "\n",
    "perspective_client = discovery.build(\n",
    "  \"commentanalyzer\",\n",
    "  \"v1alpha1\",\n",
    "  developerKey=api_key,\n",
    "  discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "  static_discovery=False,\n",
    ")\n",
    "\n",
    "with open(\"C:/Users/danie/OneDrive/Desktop/openai_youtube_api_key.txt\") as f:\n",
    "    api_key = f.readline()\n",
    "\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantifier \n",
    "def get_toxicity_score(comment):\n",
    "    analyze_request = {\n",
    "        'comment': { 'text': comment },\n",
    "        'requestedAttributes': {'TOXICITY': {}}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = perspective_client.comments().analyze(body=analyze_request).execute()\n",
    "        return float(response['attributeScores']['TOXICITY']['summaryScore']['value'])\n",
    "    except HttpError as e:\n",
    "        return [e.resp.status]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_comment_for_finetuning(row):\n",
    "    affil = row.affiliation\n",
    "    affil = 'conservative' if affil == 'R' else 'progressive'\n",
    "    title = row.video_title\n",
    "    desc = row.video_description\n",
    "    comment = row.comment_text\n",
    "    formatted = {\"messages\": [{\"role\": \"system\", \"content\": f\"You are a {affil} American political commentator.\"},\n",
    "                              {\"role\": \"user\", \"content\": f\"You just watched the youtube video '{title}' with the description '{desc}'. Give your opinion on the subject matter.\"},\n",
    "                              {\"role\": \"assistant\", \"content\": comment}]}\n",
    "    return json.dumps(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_file(df, affil):\n",
    "    size = df.shape[0]\n",
    "    if affil == 'l':\n",
    "        path = f'../data/cleaned/progressive_size_{size}_train.jsonl'\n",
    "    else:\n",
    "        path = f'../data/cleaned/conservative_size_{size}_train.jsonl'\n",
    "        \n",
    "    ft_train = open(path, mode='w')\n",
    "\n",
    "    for i in range(size):\n",
    "        row_dic = format_comment_for_finetuning(df.iloc[i,:])\n",
    "        ft_train.write(row_dic)\n",
    "        ft_train.write('\\n')\n",
    "    \n",
    "    print(f\"Successfully wrote size {affil} {size} training file.\")\n",
    "    \n",
    "    return path\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['channel_id', 'channel_title', 'affiliation', 'video_id', 'video_title',\n",
       "       'video_description', 'comment_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df = pd.read_csv(\"../data/cleaned/channel_subset_with_comments.csv\", index_col='comment_id')\n",
    "comments_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 33762 entries, Ugxtc_P8-7EmyHXAaF14AaABAg to UgxzzRFwm9vU6PRQtcl4AaABAg.9IsI0tTqTMR9IsJNADMXAb\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   channel_id         33762 non-null  object\n",
      " 1   channel_title      33762 non-null  object\n",
      " 2   affiliation        33762 non-null  object\n",
      " 3   video_id           33762 non-null  object\n",
      " 4   video_title        33762 non-null  object\n",
      " 5   video_description  33762 non-null  object\n",
      " 6   comment_text       33762 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 2.1+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 42706 entries, UgzxGyGWCRYlN6MsV5l4AaABAg to UgwWdIXwRecT8RRGoZ14AaABAg.9IAyY08RTtV9IB-WsSjP9A\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   channel_id         42706 non-null  object\n",
      " 1   channel_title      42706 non-null  object\n",
      " 2   affiliation        42706 non-null  object\n",
      " 3   video_id           42706 non-null  object\n",
      " 4   video_title        42706 non-null  object\n",
      " 5   video_description  42706 non-null  object\n",
      " 6   comment_text       42706 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 2.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Right data will be from Turning Point USA\n",
    "right_comments = comments_df.loc[comments_df.affiliation == 'R']\n",
    "# Left comments will be from The Young Turks \n",
    "left_comments =comments_df.loc[comments_df.affiliation == \"L\"]\n",
    "\n",
    "print(right_comments.info())\n",
    "print(left_comments.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25, 90, 328, 1189, 4311, 15625]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sizes = np.logspace(2, 6, 6, base=5).astype(int).tolist()\n",
    "model_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote size l 5 training file.\n",
      "Successfully wrote size r 5 training file.\n",
      "Successfully wrote size l 25 training file.\n",
      "Successfully wrote size r 25 training file.\n",
      "Successfully wrote size l 125 training file.\n",
      "Successfully wrote size r 125 training file.\n",
      "Successfully wrote size l 625 training file.\n",
      "Successfully wrote size r 625 training file.\n",
      "Successfully wrote size l 3125 training file.\n",
      "Successfully wrote size r 3125 training file.\n",
      "['../data/cleaned/progressive_size_5_train.jsonl', '../data/cleaned/conservative_size_5_train.jsonl', '../data/cleaned/progressive_size_25_train.jsonl', '../data/cleaned/conservative_size_25_train.jsonl', '../data/cleaned/progressive_size_125_train.jsonl', '../data/cleaned/conservative_size_125_train.jsonl', '../data/cleaned/progressive_size_625_train.jsonl', '../data/cleaned/conservative_size_625_train.jsonl', '../data/cleaned/progressive_size_3125_train.jsonl', '../data/cleaned/conservative_size_3125_train.jsonl']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "created_files = []\n",
    "for N in model_sizes:\n",
    "    l = left_comments.sample(n=N)\n",
    "    r = right_comments.sample(n=N)\n",
    "    \n",
    "    created_files.append(create_training_file(l, 'l'))\n",
    "    created_files.append(create_training_file(r, 'r'))\n",
    "    \n",
    "print(created_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'../data/cleaned/progressive_size_5_train.jsonl'.index('progressive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_api_ids = []\n",
    "\n",
    "for f,s in zip(created_files, [x for x in model_sizes for _ in range(2)]):\n",
    "    train_response = openai.File.create(\n",
    "        file=open(f, \"rb\"),\n",
    "        purpose='fine-tune',\n",
    "        user_provided_filename=f'{f[16:f.index(\"_size\")]}_size_{s}_training_examples'\n",
    "    )\n",
    "    file_api_ids.append(train_response['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "This fine-tune request has been rate-limited. Your organization has reached the maximum of 3 active requests (0 running, 3 pending) for the model 'gpt-3.5-turbo-0613'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danie\\OneDrive\\Desktop\\School\\Fall 2023\\Capstone\\PoliticalYouTube_LLM\\src\\300_gpt_tuning_v2.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Capstone/PoliticalYouTube_LLM/src/300_gpt_tuning_v2.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m job_ids \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Capstone/PoliticalYouTube_LLM/src/300_gpt_tuning_v2.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m f_id \u001b[39min\u001b[39;00m file_api_ids:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Capstone/PoliticalYouTube_LLM/src/300_gpt_tuning_v2.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     response_1 \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mFineTuningJob\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Capstone/PoliticalYouTube_LLM/src/300_gpt_tuning_v2.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         training_file\u001b[39m=\u001b[39;49mf_id,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Capstone/PoliticalYouTube_LLM/src/300_gpt_tuning_v2.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Capstone/PoliticalYouTube_LLM/src/300_gpt_tuning_v2.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Capstone/PoliticalYouTube_LLM/src/300_gpt_tuning_v2.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     response_2 \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mFineTuningJob\u001b[39m.\u001b[39mretrieve(response_1[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Capstone/PoliticalYouTube_LLM/src/300_gpt_tuning_v2.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     job_ids\u001b[39m.\u001b[39mappend(response_2[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\youtube_llm\\lib\\site-packages\\openai\\api_resources\\abstract\\createable_api_resource.py:57\u001b[0m, in \u001b[0;36mCreateableAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m     40\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m     48\u001b[0m ):\n\u001b[0;32m     49\u001b[0m     requestor, url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m__prepare_create_requestor(\n\u001b[0;32m     50\u001b[0m         api_key,\n\u001b[0;32m     51\u001b[0m         api_base,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m         organization,\n\u001b[0;32m     55\u001b[0m     )\n\u001b[1;32m---> 57\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m     58\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params, request_id\u001b[39m=\u001b[39;49mrequest_id\n\u001b[0;32m     59\u001b[0m     )\n\u001b[0;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39mconvert_to_openai_object(\n\u001b[0;32m     62\u001b[0m         response,\n\u001b[0;32m     63\u001b[0m         api_key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m         plain_old_data\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mplain_old_data,\n\u001b[0;32m     67\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\youtube_llm\\lib\\site-packages\\openai\\api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    280\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    291\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[1;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\youtube_llm\\lib\\site-packages\\openai\\api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    705\u001b[0m         )\n\u001b[0;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    715\u001b[0m         ),\n\u001b[0;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    717\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\youtube_llm\\lib\\site-packages\\openai\\api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    777\u001b[0m     )\n\u001b[0;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: This fine-tune request has been rate-limited. Your organization has reached the maximum of 3 active requests (0 running, 3 pending) for the model 'gpt-3.5-turbo-0613'."
     ]
    }
   ],
   "source": [
    "job_ids = []\n",
    "for f_id in file_api_ids:\n",
    "    response_1 = openai.FineTuningJob.create(\n",
    "        training_file=f_id,\n",
    "        model=\"gpt-3.5-turbo\"\n",
    "    )\n",
    "\n",
    "    response_2 = openai.FineTuningJob.retrieve(response_1['id'])\n",
    "    job_ids.append(response_2['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j_id in job_ids:\n",
    "    print(openai.FineTuningJob.retrieve(j_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
